spec "ThreatHunter" v2.2 {
  description: "AI-enhanced threat hunting platform for proactive threat detection and hypothesis-driven investigations."

  inputs:
    hunter_profile: object {
      hunter_id: string { validate: /^TH[0-9]{3}$/ }
      experience_level: enum("junior", "mid", "senior", "expert") { default: "mid" }
      specializations: array<string> { default: ["apt", "insider_threat", "malware", "lateral_movement"] }
      hunting_methodologies: array<string> { default: ["mitre_attack", "diamond_model", "kill_chain", "pyramid_of_pain"] }
      active_hunts: array<string> { default: [] }
      max_concurrent_hunts: int { default: 5 }
      preferred_data_sources: array<string> { default: ["network_logs", "endpoint_telemetry", "dns_logs", "proxy_logs"] }
    }
    
    hunting_environment: object {
      data_retention_days: int { default: 90 }
      available_data_sources: array<object> {
        schema: {
          source_name: string,
          data_type: enum("network", "endpoint", "dns", "proxy", "email", "cloud", "authentication"),
          volume_gb_per_day: float,
          retention_days: int,
          query_latency_ms: int,
          reliability_score: float
        }
      }
      hunting_tools: array<object> {
        schema: {
          tool_name: string,
          tool_type: enum("siem", "edr", "ndr", "sandbox", "threat_intel", "custom"),
          api_available: bool,
          query_language: string,
          max_concurrent_queries: int
        }
      }
      compute_resources: object {
        cpu_cores: int { default: 16 }
        memory_gb: int { default: 64 }
        storage_tb: int { default: 10 }
        gpu_available: bool { default: false }
      }
    }
    
    threat_intelligence: object {
      feeds: array<object> {
        schema: {
          feed_name: string,
          feed_type: enum("commercial", "open_source", "government", "industry_sharing"),
          confidence_level: float,
          update_frequency_hours: int,
          ioc_types: array<string>,
          attribution_data: bool
        }
      }
      internal_intel: object {
        previous_incidents: bool { default: true }
        honeypot_data: bool { default: false }
        deception_tech: bool { default: false }
        user_behavior_baselines: bool { default: true }
      }
    }
    
    ai_models: object {
      anomaly_detector: string { default: "behavioral_anomaly_v4.3" }
      pattern_recognizer: string { default: "pattern_recognition_v3.1" }
      hypothesis_generator: string { default: "hypothesis_gen_v2.9" }
      ioc_extractor: string { default: "ioc_extraction_v3.7" }
      attribution_analyzer: string { default: "attribution_v2.4" }
      campaign_correlator: string { default: "campaign_correlation_v1.8" }
    }
    
    hunting_frameworks: object {
      mitre_attack: object {
        version: string { default: "v14.1" }
        focus_tactics: array<string> { default: ["initial_access", "persistence", "lateral_movement", "exfiltration"] }
        coverage_matrix: bool { default: true }
      }
      hypothesis_templates: array<object> {
        schema: {
          template_id: string,
          threat_type: string,
          data_requirements: array<string>,
          expected_indicators: array<string>,
          validation_criteria: array<string>,
          estimated_time_hours: int
        }
      }
    }

  computed:
    hunting_capacity: -> {
      let active_count = len(hunter_profile.active_hunts)
      let utilization = active_count / hunter_profile.max_concurrent_hunts
      return {
        active_hunts: active_count,
        capacity_utilization: utilization,
        available_slots: hunter_profile.max_concurrent_hunts - active_count,
        overloaded: utilization > 0.8,
        efficiency_score: calculate_hunting_efficiency(hunter_profile.hunter_id, 30)
      }
    }
    
    data_landscape: -> {
      let total_volume = sum(hunting_environment.available_data_sources, "volume_gb_per_day")
      let avg_latency = avg(hunting_environment.available_data_sources, "query_latency_ms")
      return {
        total_daily_volume_gb: total_volume,
        average_query_latency_ms: avg_latency,
        data_source_count: len(hunting_environment.available_data_sources),
        high_volume_sources: filter(hunting_environment.available_data_sources, lambda x: x.volume_gb_per_day > 100),
        coverage_score: calculate_data_coverage_score(hunting_environment.available_data_sources)
      }
    }
    
    threat_landscape_analysis: -> mcp.call("ai.analyze_threat_landscape", {
      hunter_specializations: hunter_profile.specializations,
      recent_intelligence: get_recent_threat_intel(7),
      organizational_context: get_organizational_threat_profile(),
      industry_threats: get_industry_specific_threats()
    })
    
    hunting_priorities: -> mcp.call("ai.generate_hunting_priorities", {
      threat_landscape: threat_landscape_analysis,
      data_availability: data_landscape,
      hunter_capacity: hunting_capacity,
      previous_hunt_results: get_recent_hunt_results(30)
    })

  events:
    on_new_hypothesis(hypothesis_data): {
      // Process new hunting hypothesis
      let hypothesis_validation = mcp.call("ai.validate_hypothesis", {
        hypothesis: hypothesis_data,
        model: ai_models.hypothesis_generator,
        context: {
          available_data: hunting_environment.available_data_sources,
          threat_intel: threat_intelligence,
          hunter_expertise: hunter_profile.specializations,
          historical_hunts: get_similar_hunts(hypothesis_data.threat_type)
        }
      })
      
      if hypothesis_validation.feasible {
        let hunt_plan = mcp.call("ai.generate_hunt_plan", {
          hypothesis: hypothesis_data,
          validation: hypothesis_validation,
          data_sources: hypothesis_validation.recommended_data_sources,
          estimated_effort: hypothesis_validation.estimated_hours,
          model: ai_models.pattern_recognizer
        })
        
        let hunt_session = actions.initiate_hunt({
          hypothesis: hypothesis_data,
          plan: hunt_plan,
          hunter: hunter_profile.hunter_id,
          priority: hypothesis_validation.priority,
          estimated_duration: hunt_plan.estimated_hours
        })
        
        actions.setup_hunting_environment(hunt_session.id, hunt_plan.required_tools)
        actions.begin_data_collection(hunt_session.id, hunt_plan.data_queries)
        
        if hypothesis_validation.priority == "critical" {
          actions.notify_soc_team("critical_hunt_initiated", hunt_session)
        }
      } else {
        actions.log_hypothesis_rejection(hypothesis_data, hypothesis_validation.rejection_reason)
      }
    }
    
    on_anomaly_detected(anomaly_data): {
      // Handle behavioral or statistical anomalies
      let anomaly_analysis = mcp.call("ai.analyze_anomaly", {
        anomaly: anomaly_data,
        model: ai_models.anomaly_detector,
        context: {
          baseline_behavior: get_baseline_behavior(anomaly_data.entity),
          peer_comparison: get_peer_behavior_analysis(anomaly_data.entity_type),
          temporal_context: get_temporal_context(anomaly_data.timestamp),
          threat_context: get_relevant_threat_intel(anomaly_data)
        }
      })
      
      if anomaly_analysis.threat_score > 0.6 {
        let investigation_plan = mcp.call("ai.generate_investigation_plan", {
          anomaly: anomaly_data,
          analysis: anomaly_analysis,
          model: ai_models.pattern_recognizer,
          available_data: hunting_environment.available_data_sources
        })
        
        let investigation = actions.launch_investigation({
          trigger: "anomaly_detection",
          anomaly_id: anomaly_data.id,
          threat_score: anomaly_analysis.threat_score,
          investigation_plan: investigation_plan,
          assigned_hunter: hunter_profile.hunter_id
        })
        
        actions.execute_investigation_queries(investigation.id, investigation_plan.queries)
        
        if anomaly_analysis.threat_score > 0.8 {
          actions.escalate_to_incident_response(investigation, anomaly_analysis)
        }
      } else {
        actions.update_behavioral_baseline(anomaly_data.entity, anomaly_data)
      }
    }
    
    on_hunt_progress_update(progress_data): {
      // Handle ongoing hunt progress and findings
      let hunt = get_hunt(progress_data.hunt_id)
      let findings_analysis = mcp.call("ai.analyze_hunt_findings", {
        hunt_id: progress_data.hunt_id,
        current_findings: progress_data.findings,
        model: ai_models.pattern_recognizer,
        hypothesis: hunt.hypothesis,
        progress_percentage: progress_data.completion_percentage
      })
      
      if findings_analysis.significant_findings {
        let ioc_extraction = mcp.call("ai.extract_iocs", {
          findings: findings_analysis.significant_findings,
          model: ai_models.ioc_extractor,
          context: hunt.hypothesis,
          confidence_threshold: 0.7
        })
        
        if len(ioc_extraction.high_confidence_iocs) > 0 {
          actions.generate_threat_intelligence(hunt.id, ioc_extraction)
          actions.update_detection_rules(ioc_extraction.high_confidence_iocs)
          
          let attribution_analysis = mcp.call("ai.analyze_attribution", {
            iocs: ioc_extraction.high_confidence_iocs,
            findings: findings_analysis.significant_findings,
            model: ai_models.attribution_analyzer,
            threat_intel_feeds: threat_intelligence.feeds
          })
          
          if attribution_analysis.campaign_match {
            actions.correlate_with_known_campaigns(hunt.id, attribution_analysis)
          }
        }
      }
      
      if progress_data.completion_percentage >= 100 {
        actions.finalize_hunt(progress_data.hunt_id, findings_analysis)
      } else if findings_analysis.pivot_recommended {
        actions.pivot_hunt_direction(progress_data.hunt_id, findings_analysis.pivot_suggestion)
      }
    }
    
    on_threat_intel_update(intel_update): {
      // Process new threat intelligence for hunting opportunities
      let relevance_analysis = mcp.call("ai.assess_intel_relevance", {
        intelligence: intel_update,
        organizational_context: get_organizational_context(),
        current_hunts: hunter_profile.active_hunts,
        hunter_specializations: hunter_profile.specializations,
        model: ai_models.pattern_recognizer
      })
      
      if relevance_analysis.hunting_opportunity {
        let hypothesis_suggestions = mcp.call("ai.generate_hypotheses_from_intel", {
          intelligence: intel_update,
          relevance: relevance_analysis,
          model: ai_models.hypothesis_generator,
          data_availability: data_landscape
        })
        
        for suggestion in hypothesis_suggestions.high_priority {
          actions.queue_hypothesis_for_review(suggestion, "intel_driven")
        }
        
        // Check if any active hunts should be updated
        for hunt_id in hunter_profile.active_hunts {
          let hunt_update = mcp.call("ai.assess_hunt_intel_impact", {
            hunt_id: hunt_id,
            new_intelligence: intel_update,
            model: ai_models.pattern_recognizer
          })
          
          if hunt_update.should_modify_hunt {
            actions.update_hunt_parameters(hunt_id, hunt_update.modifications)
          }
        }
      }
    }
    
    on_campaign_correlation(correlation_event): {
      // Handle potential campaign correlations across multiple hunts
      let campaign_analysis = mcp.call("ai.analyze_campaign_correlation", {
        correlation_data: correlation_event,
        active_hunts: get_hunts_by_hunter(hunter_profile.hunter_id),
        historical_campaigns: get_known_campaigns(),
        model: ai_models.campaign_correlator
      })
      
      if campaign_analysis.campaign_identified {
        let campaign_hunt = actions.initiate_campaign_hunt({
          campaign_id: campaign_analysis.campaign_id,
          correlated_hunts: correlation_event.hunt_ids,
          campaign_characteristics: campaign_analysis.characteristics,
          priority: "high",
          hunter: hunter_profile.hunter_id
        })
        
        actions.consolidate_hunt_findings(correlation_event.hunt_ids, campaign_hunt.id)
        actions.expand_hunt_scope(campaign_hunt.id, campaign_analysis.recommended_scope)
        
        if campaign_analysis.severity == "critical" {
          actions.alert_threat_intelligence_team(campaign_analysis)
          actions.coordinate_with_other_hunters(campaign_analysis.campaign_id)
        }
      }
    }

  actions:
    initiate_hunt(hunt_config: object) -> {
      let hunt_session = create_hunt_session({
        id: generate_hunt_id(),
        hypothesis: hunt_config.hypothesis,
        plan: hunt_config.plan,
        hunter: hunt_config.hunter,
        priority: hunt_config.priority,
        status: "active",
        created_at: now(),
        estimated_completion: now() + (hunt_config.estimated_duration * 3600)
      })
      
      update_hunter_active_hunts(hunter_profile.hunter_id, hunt_session.id)
      log_audit_event("hunt_initiated", hunt_session.id, hunter_profile.hunter_id)
      return hunt_session
    }
    
    setup_hunting_environment(hunt_id: string, required_tools: array<string>) -> {
      let environment = create_isolated_hunting_environment({
        hunt_id: hunt_id,
        tools: required_tools,
        data_access_permissions: get_hunt_data_permissions(hunt_id),
        compute_allocation: allocate_compute_resources(hunting_environment.compute_resources, 0.3)
      })
      
      for tool in required_tools {
        configure_hunting_tool(tool, hunt_id, environment.workspace_id)
      }
      
      return environment
    }
    
    begin_data_collection(hunt_id: string, data_queries: array<object>) -> {
      let collection_jobs = []
      for query in data_queries {
        let job = schedule_data_query({
          hunt_id: hunt_id,
          query: query.query_text,
          data_source: query.source,
          priority: query.priority,
          estimated_runtime: query.estimated_minutes,
          output_format: "structured"
        })
        collection_jobs = append(collection_jobs, job)
      }
      
      monitor_collection_progress(hunt_id, collection_jobs)
      return collection_jobs
    }
    
    launch_investigation(investigation_config: object) -> {
      let investigation = create_investigation({
        id: generate_investigation_id(),
        trigger: investigation_config.trigger,
        threat_score: investigation_config.threat_score,
        plan: investigation_config.investigation_plan,
        assigned_hunter: investigation_config.assigned_hunter,
        status: "active",
        created_at: now()
      })
      
      log_audit_event("investigation_launched", investigation.id, hunter_profile.hunter_id)
      return investigation
    }
    
    generate_threat_intelligence(hunt_id: string, ioc_data: object) -> {
      let threat_intel = compile_threat_intelligence({
        source_hunt: hunt_id,
        iocs: ioc_data.high_confidence_iocs,
        context: ioc_data.context,
        confidence_scores: ioc_data.confidence_scores,
        attribution: ioc_data.attribution_hints,
        generated_by: hunter_profile.hunter_id,
        generated_at: now(),
        sharing_level: determine_sharing_level(ioc_data.sensitivity)
      })
      
      store_threat_intelligence(threat_intel)
      share_with_threat_intel_platform(threat_intel)
      
      if threat_intel.sharing_level == "external" {
        submit_to_industry_sharing(threat_intel)
      }
    }
    
    update_detection_rules(iocs: array<object>) -> {
      let rule_updates = []
      for ioc in iocs {
        let detection_rule = generate_detection_rule({
          ioc: ioc,
          confidence: ioc.confidence_score,
          context: ioc.context,
          rule_type: determine_rule_type(ioc.type),
          severity: map_confidence_to_severity(ioc.confidence_score)
        })
        
        rule_updates = append(rule_updates, detection_rule)
      }
      
      deploy_detection_rules(rule_updates)
      notify_soc_team("new_detection_rules", rule_updates)
    }
    
    finalize_hunt(hunt_id: string, final_analysis: object) -> {
      let hunt_report = generate_hunt_report({
        hunt_id: hunt_id,
        findings: final_analysis,
        iocs_discovered: get_hunt_iocs(hunt_id),
        lessons_learned: final_analysis.lessons_learned,
        recommendations: final_analysis.recommendations,
        hunter: hunter_profile.hunter_id,
        completed_at: now()
      })
      
      store_hunt_report(hunt_report)
      update_hunter_metrics(hunter_profile.hunter_id, hunt_report.metrics)
      remove_from_active_hunts(hunter_profile.hunter_id, hunt_id)
      
      if final_analysis.follow_up_required {
        actions.schedule_follow_up_hunt(hunt_id, final_analysis.follow_up_recommendations)
      }
    }
    
    pivot_hunt_direction(hunt_id: string, pivot_suggestion: object) -> {
      let current_hunt = get_hunt(hunt_id)
      let updated_plan = modify_hunt_plan(current_hunt.plan, pivot_suggestion)
      
      update_hunt_record(hunt_id, {
        plan: updated_plan,
        pivot_reason: pivot_suggestion.reason,
        pivoted_at: now(),
        pivot_count: increment_pivot_count(hunt_id)
      })
      
      log_audit_event("hunt_pivoted", hunt_id, hunter_profile.hunter_id)
    }

  constraints:
    assert hunter_profile.max_concurrent_hunts > 0
    assert hunter_profile.max_concurrent_hunts <= 10
    ensure len(hunter_profile.specializations) > 0
    assert hunting_environment.data_retention_days > 0
    ensure len(hunting_environment.available_data_sources) > 0
    assert hunting_environment.compute_resources.cpu_cores > 0
    assert hunting_environment.compute_resources.memory_gb > 0
    
    // Capacity constraints
    ensure len(hunter_profile.active_hunts) <= hunter_profile.max_concurrent_hunts
    assert len(threat_intelligence.feeds) > 0
    
    // Data quality constraints
    ensure all(hunting_environment.available_data_sources, lambda x: x.reliability_score >= 0.5)
    ensure hunting_environment.data_retention_days >= 30

  lifecycle:
    on_start: {
      actions.initialize_hunting_session(hunter_profile)
      actions.sync_threat_intelligence_feeds()
      actions.validate_data_source_connectivity()
      actions.load_active_hunts(hunter_profile.hunter_id)
      log_audit_event("hunter_session_started", hunter_profile.hunter_id)
    }
    
    on_shift_end: {
      actions.save_hunt_progress()
      actions.handoff_active_investigations()
      actions.generate_shift_summary()
      log_audit_event("hunter_shift_ended", hunter_profile.hunter_id)
    }
    
    on_error: {
      actions.preserve_hunt_state()
      actions.escalate_system_error()
      actions.fallback_to_manual_hunting()
      notify_hunt_manager("system_error", error_details)
    }

  extensions:
    use "mcp" {
      endpoints: ["ai.analyze_threat_landscape", "ai.generate_hunting_priorities", "ai.validate_hypothesis",
                 "ai.generate_hunt_plan", "ai.analyze_anomaly", "ai.generate_investigation_plan",
                 "ai.analyze_hunt_findings", "ai.extract_iocs", "ai.analyze_attribution",
                 "ai.assess_intel_relevance", "ai.generate_hypotheses_from_intel", "ai.analyze_campaign_correlation"]
    }
    
    use "threat_intelligence" {
      feeds: threat_intelligence.feeds
      auto_correlation: true
      ioc_enrichment: true
    }
    
    use "hunting_platform" {
      tools: hunting_environment.hunting_tools
      data_sources: hunting_environment.available_data_sources
      query_optimization: true
    }
    
    use "mitre_attack" {
      version: hunting_frameworks.mitre_attack.version
      coverage_tracking: true
      technique_mapping: true
    }
}
